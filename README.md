# ğŸ¯ Student Performance Prediction Pipeline

This project is a complete **Machine Learning pipeline** for predicting student performance based on various demographic and academic features.  
It includes data preprocessing, model training, and prediction functionality.

---

## ğŸ“‚ Project Structure

```plaintext
project/
â”‚
â”œâ”€â”€ artifacts/                     # Stores training data, model, preprocessor
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ model.pkl
â”‚   â”œâ”€â”€ preprocessor.pkl
â”‚
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ exception.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ pipeline/
â”‚       â”œâ”€â”€ predict_pipeline.py
â”‚       â”œâ”€â”€ train_pipeline.py
â”‚
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ requirements.txt                # Python dependencies
```

## ğŸ“Š Dataset

Sample dataset (`train.csv`) used in `artifacts/`:

gender,race_ethnicity,parental_level_of_education,lunch,test_preparation_course,math_score,reading_score,writing_score

female,group B,bachelor's degree,standard,none,72,72,74

female,group C,some college,standard,completed,69,90,88

female,group B,master's degree,standard,none,90,95,93


# ğŸ“‚ Project Structure Overview

```mermaid
graph TD

A[train_pipeline.py] --> B[src/components/model_trainer.py]
A --> C[src/utils.py]
A --> D[src/logger.py]
A --> E[src/exception.py]
A --> F[artifacts/train.csv]

B -->|Uses| G[ML Models & Training Logic]
C -->|Provides| H[load_data / save_object / preprocess_data]
D -->|Handles| I[Logging Configuration]
E -->|Handles| J[Custom Exception Handling]

subgraph Artifacts
    F
end
```

# âš™ï¸ Installation

    Clone the repository

git clone https://github.com/yourusername/student-performance-pipeline.git

cd student-performance-pipeline

    Create a virtual environment

python -m venv venv

source venv/bin/activate  # On Mac/Linux

venv\Scripts\activate     # On Windows

    Install dependencies

pip install -r requirements.txt

##ğŸš€ Running the Training Pipeline

To train the model with the dataset in artifacts/train.csv:

python src/pipeline/train_pipeline.py

This will:

    Load and preprocess the training data

    Train the model

    Save the trained model (model.pkl) and preprocessor (preprocessor.pkl) in artifacts/

# ğŸ”® Making Predictions

Example usage:

from src.pipeline.predict_pipeline import CustomData, PredictPipeline

# Prepare custom input data

data = CustomData(
    gender="female",
    
    race_ethnicity="group B",
    
    parental_level_of_education="bachelor's degree",
    
    lunch="standard",
    
    test_preparation_course="none",
    
    reading_score=72,
    
    writing_score=74
    
)

# Convert to DataFrame
df = data.get_data_as_data_frame()

# Load model and make prediction

predict_pipeline = PredictPipeline()

result = predict_pipeline.predict(df)

print(f"Predicted Math Score: {result}")

# ğŸ“œ Logging

Logging is enabled in the train_pipeline and other scripts using:

from src.logger import logging

Logs provide step-by-step execution tracking for easier debugging.
# ğŸ“Œ Notes

    Ensure your CSV file matches the column structure expected by the preprocessing function.

    The CustomData class must match your datasetâ€™s feature names exactly.

    artifacts/ will be automatically updated when retraining.

